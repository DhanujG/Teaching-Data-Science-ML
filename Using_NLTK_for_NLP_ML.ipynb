{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "15ac2ca1da7d9bd3bea307d5ea7ff71b4737df7134aa4ab9e215049dfe65c2a6"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9J8hyaQDSb7",
        "outputId": "322c6b2f-0ed1-4e0d-f569-5a42da9d2ecd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\dhanu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\dhanu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#https://earthobservatory.nasa.gov/images/148021/deforestation-in-papua\n",
        "#https://docs.google.com/document/d/1ykbfbtzKm7ytzyxB05_n_rCXG6GHSb88-By6WU13sZA/edit?usp=sharing\n",
        "\n",
        "\n",
        "article = [\"Though it covers just 1 percent of Earth’s land surfaces, Indonesia’s rainforest is believed to shelter 10 percent of the world’s known plant species, 12 percent of mammal species, and 17 percent of bird species. Spread across 18,000 islands, it covers an area large enough to make it the world’s third-largest rainforest, trailing only those in the Amazon and Congo basins.While satellite data indicate that Indonesia has had high rates of forest loss in recent decades, the situation seems to be changing. Deforestation declined significantly between 2017-2019, according to data from Global Forest Watch. The forest change data used in the analysis was collected by Landsat satellites and processed by a team from the University of Maryland.But even as deforestation slows on major Indonesian islands such as Sumatra and Kalimantan, there are signs of a shift to other areas. One of those areas is Papua (also called Western New Guinea). Papua’s rugged terrain and scarcity of transportation infrastructure has led to less development and economic growth than in other parts of Indonesia. But in some parts of the island, there has been noticeable new activity in the past decade.The images above show forest clearing along the Digul River near Banamepe, an area that was cleared between 2011 and 2016. The data used in the earlier image (left) was acquired by the Thematic Mapper (TM) on Landsat 5 in 2002; the later image (right) was acquired by the Operational Land Imager (OLI) on Landsat 8 in 2020.The map below, based on forest change data from the University of Maryland, shows part of southern Papua where lowland rainforest and swamp forest have been cleared to establish several large plantations. While large-scale deforestation has been happening in this area for about two decades, several particularly large plots were cleared in the past few years, including some near the river town Tanahmerah.The smaller, more scattered clearings along rivers are likely associated with selective logging, natural shifts in water courses, and small-scale clearing by subsistence farmers, explained remote sensing scientist David Gaveau, the author of a new study about deforestation trends in Papua. In the lower third of the map, an area where forests transition into the Trans-Fly savanna and grasslands, some of the changes are likely associated with seasonal fires.“The slowdown in Sumatra and Kalimantan is due, at least in part, to the exhaustion of available suitable land for plantation agriculture and increasing land prices on these islands,” explained Kemen Austin, an analyst with the non-profit research organization RTI International and the author of a 2019 study about the drivers of deforestation in Indonesia. “Papua is seen as the next frontier, and recent investments in infrastructure have made plantation agriculture in the region more economically compelling.”According to Gaveau’s analysis of two decades of Landsat data, nearly 750,000 hectares of forest were cleared in Papua between 2001-2019—about 2 percent of the island’s forests. Of that total, the analysis found that about 28 percent was cleared for industrial plantations (oil palm and pulpwood), 23 percent for shifting cultivation, 16 percent for selective logging, 11 percent for rivers and lakes expanding or changing course, 15 percent for urban expansion and roads, 5 percent for fires, and 2 percent for mining. (Shifting cultivation is a type of farming where fields are only used temporarily and then left to regrow naturally for a number of years before being cleared again.)Biological surveys have been rare on the relatively undeveloped New Guinea, so the island’s immense biodiversity remains only partly catalogued and understood. Since the island was once connected to Australia, it is home to unusual marsupials, such as tree kangaroos and forest wallabies. Among the island’s more notable animals are two species of egg-laying mammals (monotremes) called echidna.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#remove punctuation from string\n",
        "def remove_punct(text):\n",
        "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text_nopunct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#remove stopwords download\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "\n",
        "# Function to remove Stopwords\n",
        "def remove_stopwords(tokenized_list):\n",
        "    text = [word for word in tokenized_list if word not in stopword]# To remove all stopwords\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Though', 'covers', '1', 'percent', 'Earth', '’', 'land', 'surfaces', 'Indonesia', '’', 'rainforest', 'believed', 'shelter', '10', 'percent', 'world', '’', 'known', 'plant', 'species', '12', 'percent', 'mammal', 'species', '17', 'percent', 'bird', 'species', 'Spread', 'across', '18000', 'islands', 'covers', 'area', 'large', 'enough', 'make', 'world', '’', 'thirdlargest', 'rainforest', 'trailing', 'Amazon', 'Congo', 'basinsWhile', 'satellite', 'data', 'indicate', 'Indonesia', 'high', 'rates', 'forest', 'loss', 'recent', 'decades', 'situation', 'seems', 'changing', 'Deforestation', 'declined', 'significantly', '20172019', 'according', 'data', 'Global', 'Forest', 'Watch', 'The', 'forest', 'change', 'data', 'used', 'analysis', 'collected', 'Landsat', 'satellites', 'processed', 'team', 'University', 'MarylandBut', 'even', 'deforestation', 'slows', 'major', 'Indonesian', 'islands', 'Sumatra', 'Kalimantan', 'signs', 'shift', 'areas', 'One', 'areas', 'Papua', 'also', 'called', 'Western', 'New', 'Guinea', 'Papua', '’', 'rugged', 'terrain', 'scarcity', 'transportation', 'infrastructure', 'led', 'less', 'development', 'economic', 'growth', 'parts', 'Indonesia', 'But', 'parts', 'island', 'noticeable', 'new', 'activity', 'past', 'decadeThe', 'images', 'show', 'forest', 'clearing', 'along', 'Digul', 'River', 'near', 'Banamepe', 'area', 'cleared', '2011', '2016', 'The', 'data', 'used', 'earlier', 'image', 'left', 'acquired', 'Thematic', 'Mapper', 'TM', 'Landsat', '5', '2002', 'later', 'image', 'right', 'acquired', 'Operational', 'Land', 'Imager', 'OLI', 'Landsat', '8', '2020The', 'map', 'based', 'forest', 'change', 'data', 'University', 'Maryland', 'shows', 'part', 'southern', 'Papua', 'lowland', 'rainforest', 'swamp', 'forest', 'cleared', 'establish', 'several', 'large', 'plantations', 'While', 'largescale', 'deforestation', 'happening', 'area', 'two', 'decades', 'several', 'particularly', 'large', 'plots', 'cleared', 'past', 'years', 'including', 'near', 'river', 'town', 'TanahmerahThe', 'smaller', 'scattered', 'clearings', 'along', 'rivers', 'likely', 'associated', 'selective', 'logging', 'natural', 'shifts', 'water', 'courses', 'smallscale', 'clearing', 'subsistence', 'farmers', 'explained', 'remote', 'sensing', 'scientist', 'David', 'Gaveau', 'author', 'new', 'study', 'deforestation', 'trends', 'Papua', 'In', 'lower', 'third', 'map', 'area', 'forests', 'transition', 'TransFly', 'savanna', 'grasslands', 'changes', 'likely', 'associated', 'seasonal', 'fires', '“', 'The', 'slowdown', 'Sumatra', 'Kalimantan', 'due', 'least', 'part', 'exhaustion', 'available', 'suitable', 'land', 'plantation', 'agriculture', 'increasing', 'land', 'prices', 'islands', '”', 'explained', 'Kemen', 'Austin', 'analyst', 'nonprofit', 'research', 'organization', 'RTI', 'International', 'author', '2019', 'study', 'drivers', 'deforestation', 'Indonesia', '“', 'Papua', 'seen', 'next', 'frontier', 'recent', 'investments', 'infrastructure', 'made', 'plantation', 'agriculture', 'region', 'economically', 'compelling', '”', 'According', 'Gaveau', '’', 'analysis', 'two', 'decades', 'Landsat', 'data', 'nearly', '750000', 'hectares', 'forest', 'cleared', 'Papua', '20012019—about', '2', 'percent', 'island', '’', 'forests', 'Of', 'total', 'analysis', 'found', '28', 'percent', 'cleared', 'industrial', 'plantations', 'oil', 'palm', 'pulpwood', '23', 'percent', 'shifting', 'cultivation', '16', 'percent', 'selective', 'logging', '11', 'percent', 'rivers', 'lakes', 'expanding', 'changing', 'course', '15', 'percent', 'urban', 'expansion', 'roads', '5', 'percent', 'fires', '2', 'percent', 'mining', 'Shifting', 'cultivation', 'type', 'farming', 'fields', 'used', 'temporarily', 'left', 'regrow', 'naturally', 'number', 'years', 'cleared', 'againBiological', 'surveys', 'rare', 'relatively', 'undeveloped', 'New', 'Guinea', 'island', '’', 'immense', 'biodiversity', 'remains', 'partly', 'catalogued', 'understood', 'Since', 'island', 'connected', 'Australia', 'home', 'unusual', 'marsupials', 'tree', 'kangaroos', 'forest', 'wallabies', 'Among', 'island', '’', 'notable', 'animals', 'two', 'species', 'egglaying', 'mammals', 'monotremes', 'called', 'echidna']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#remove punctuation from article\n",
        "article[0] = remove_punct(article[0])\n",
        "\n",
        "#tokenize article\n",
        "article_tokens = nltk.word_tokenize(article[0])\n",
        "\n",
        "#remove stopwords\n",
        "article_tokens = remove_stopwords(article_tokens)\n",
        "\n",
        "\n",
        "print(article_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percent: 12\n’: 9\nforest: 7\ndata: 6\nPapua: 6\ncleared: 6\nisland: 5\nIndonesia: 4\nspecies: 4\narea: 4\nLandsat: 4\ndeforestation: 4\nland: 3\nrainforest: 3\nislands: 3\nlarge: 3\ndecades: 3\nThe: 3\nused: 3\nanalysis: 3\ntwo: 3\ncovers: 2\nworld: 2\nrecent: 2\nchanging: 2\nchange: 2\nUniversity: 2\nSumatra: 2\nKalimantan: 2\nareas: 2\ncalled: 2\nNew: 2\nGuinea: 2\ninfrastructure: 2\nparts: 2\nnew: 2\npast: 2\nclearing: 2\nalong: 2\nnear: 2\nimage: 2\nleft: 2\nacquired: 2\n5: 2\nmap: 2\npart: 2\nseveral: 2\nplantations: 2\nyears: 2\nrivers: 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Count Frequency of each token\n",
        "Article_Word_Frequency = nltk.FreqDist(article_tokens)\n",
        "\n",
        "#Print out 50 most common words\n",
        "for word, frequency in Article_Word_Frequency.most_common(50):\n",
        "    print(u'{}: {}'.format(word, frequency))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Below are more Examples from old workbook fo NLTK usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctG4VaPGELcH"
      },
      "source": [
        "sentences_shorter = [\"The cat sat on the hat?\", \"The dog ate the cat and the hat.\", \"The hat ate the dog and the cat\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvSJkj_8EPfl",
        "outputId": "76a578de-e9a4-4f70-a5f4-dace0e1aed2b"
      },
      "source": [
        "# tokenize\n",
        "tokens = nltk.word_tokenize(sentences_shorter[0])\n",
        "print(tokens)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'cat', 'sat', 'on', 'the', 'hat', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op73M5qREXzC",
        "outputId": "25742c23-0bc8-4185-dee3-74e385e2f373"
      },
      "source": [
        "# what are the parts of speech? EXAMPLE\n",
        "pos = nltk.pos_tag(tokens)\n",
        "\n",
        "\n",
        "print(pos)\n",
        "\n",
        "\n",
        "key = 'dog'\n",
        "count = 0\n",
        "for index,tuple in enumerate (pos):\n",
        "\t\t\t\tif (tuple[0] == key) or (tuple[1] == key):\n",
        "\t\t\t\t\tcount = count + 1\n",
        "print(count)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('cat', 'NN'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('hat', 'NN'), ('?', '.')]\n0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzo1dXRSEe5o",
        "outputId": "381a173c-1c09-43c7-d865-5d58aee79b39"
      },
      "source": [
        "# let's count the occurrence of each word\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(sentences_shorter)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(X.toarray())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'ate', 'cat', 'dog', 'hat', 'on', 'sat', 'the']\n[[0 0 1 0 1 1 1 2]\n [1 1 1 1 1 0 0 3]\n [1 1 1 1 1 0 0 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh9Xzl0wEssj",
        "outputId": "919e62d5-60df-44a6-f78c-17ff41c3393b"
      },
      "source": [
        "# tf-idf \n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(sentences_shorter)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(X.toarray())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'ate', 'cat', 'dog', 'hat', 'on', 'sat', 'the']\n[[0.         0.         0.2919351  0.         0.2919351  0.49428908\n  0.49428908 0.58387019]\n [0.32217861 0.32217861 0.25020043 0.32217861 0.25020043 0.\n  0.         0.7506013 ]\n [0.32217861 0.32217861 0.25020043 0.32217861 0.25020043 0.\n  0.         0.7506013 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNva2BBlDnyg"
      },
      "source": [
        "sentences = [\"Do you like amusement parks?\",\n",
        "             \"Well, I sure do. To amuse myself, I went twice last spring.\",\n",
        "             \"My most MEMORABLE moment was riding on the Caterpillar, which is a gigantic roller coaster high above the ground.\",\n",
        "             \"When I saw how high the Caterpillar rose into the bright blue sky I knew it was for me.\", \n",
        "             \"After waiting in line for thirty minutes, I made it to the front where the man measured my height to see if I was tall enough.\",\n",
        "             \"I gave the man my coins, asked for change, and jumped on the cart. Tick, tick, tick, the Caterpillar climbed slowly up the tracks.\",\n",
        "             \"It went SO high I could see the parking lot.\",\n",
        "             \"Boy was I SCARED!\",\n",
        "             \"I thought to myself, There’s no turning back now.\",\n",
        "             \"People were so scared they screamed as we swiftly zoomed fast, fast, and faster along the tracks.\",\n",
        "             \"As quickly as it started, the Caterpillar came to a stop.\",\n",
        "             \"Unfortunately, it was time to pack the car and drive home.\",\n",
        "             \"That night I dreamt of the wild ride on the Caterpillar.\",\n",
        "             \"Taking a trip to the amusement park and riding on the Caterpillar was my MOST memorable moment ever!\"]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka4KaEJZD7Mr"
      },
      "source": [
        "# tokenize\n",
        "tokens = nltk.word_tokenize(sentences[0])\n",
        "print(tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Do', 'you', 'like', 'amusement', 'parks', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNKe94AmD8T8"
      },
      "source": [
        "# let's look at the parts of speech again\n",
        "nltk.pos_tag(tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Do', 'VBP'),\n",
              " ('you', 'PRP'),\n",
              " ('like', 'IN'),\n",
              " ('amusement', 'NN'),\n",
              " ('parks', 'NNS'),\n",
              " ('?', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFoqAsREEWpQ"
      },
      "source": [
        "# Automatic readibility index\n",
        "def ari(data):\n",
        "  print (\"Statistics:\")\n",
        "  # how many sentences?\n",
        "  num_sents = len(data)\n",
        "  print (\"  %d sentences\" %num_sents)\n",
        "  \n",
        "  # create a list of all words\n",
        "  words = \" \".join(data).split()\n",
        "  # remove punctuation and make lower case\n",
        "  words = [w.translate(str.maketrans('', '', string.punctuation)).lower() for w in words]\n",
        "  num_words = len(words)\n",
        "  # how many words?\n",
        "  print (\"  %d words\" %num_words)\n",
        "\n",
        "  # list of characters, instead of words, do not include space\n",
        "  chars = [c for w in words for c in w]\n",
        "  print (chars)\n",
        "  # how many characters?\n",
        "  num_chars = len(chars)\n",
        "  print (\"  %d characters\" %num_chars)\n",
        "\n",
        "  # calculate Automated Readability Index (Lecture 2)\n",
        "  char_by_words = num_chars/num_words\n",
        "  words_by_sent = num_words/num_sents\n",
        "  ari = 4.71 * char_by_words + words_by_sent - 21.43\n",
        "  print (ari)\n",
        "\n",
        "\n",
        "\n",
        "ari(sentences)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics:\n  14 sentences\n  196 words\n['d', 'o', 'y', 'o', 'u', 'l', 'i', 'k', 'e', 'a', 'm', 'u', 's', 'e', 'm', 'e', 'n', 't', 'p', 'a', 'r', 'k', 's', 'w', 'e', 'l', 'l', 'i', 's', 'u', 'r', 'e', 'd', 'o', 't', 'o', 'a', 'm', 'u', 's', 'e', 'm', 'y', 's', 'e', 'l', 'f', 'i', 'w', 'e', 'n', 't', 't', 'w', 'i', 'c', 'e', 'l', 'a', 's', 't', 's', 'p', 'r', 'i', 'n', 'g', 'm', 'y', 'm', 'o', 's', 't', 'm', 'e', 'm', 'o', 'r', 'a', 'b', 'l', 'e', 'm', 'o', 'm', 'e', 'n', 't', 'w', 'a', 's', 'r', 'i', 'd', 'i', 'n', 'g', 'o', 'n', 't', 'h', 'e', 'c', 'a', 't', 'e', 'r', 'p', 'i', 'l', 'l', 'a', 'r', 'w', 'h', 'i', 'c', 'h', 'i', 's', 'a', 'g', 'i', 'g', 'a', 'n', 't', 'i', 'c', 'r', 'o', 'l', 'l', 'e', 'r', 'c', 'o', 'a', 's', 't', 'e', 'r', 'h', 'i', 'g', 'h', 'a', 'b', 'o', 'v', 'e', 't', 'h', 'e', 'g', 'r', 'o', 'u', 'n', 'd', 'w', 'h', 'e', 'n', 'i', 's', 'a', 'w', 'h', 'o', 'w', 'h', 'i', 'g', 'h', 't', 'h', 'e', 'c', 'a', 't', 'e', 'r', 'p', 'i', 'l', 'l', 'a', 'r', 'r', 'o', 's', 'e', 'i', 'n', 't', 'o', 't', 'h', 'e', 'b', 'r', 'i', 'g', 'h', 't', 'b', 'l', 'u', 'e', 's', 'k', 'y', 'i', 'k', 'n', 'e', 'w', 'i', 't', 'w', 'a', 's', 'f', 'o', 'r', 'm', 'e', 'a', 'f', 't', 'e', 'r', 'w', 'a', 'i', 't', 'i', 'n', 'g', 'i', 'n', 'l', 'i', 'n', 'e', 'f', 'o', 'r', 't', 'h', 'i', 'r', 't', 'y', 'm', 'i', 'n', 'u', 't', 'e', 's', 'i', 'm', 'a', 'd', 'e', 'i', 't', 't', 'o', 't', 'h', 'e', 'f', 'r', 'o', 'n', 't', 'w', 'h', 'e', 'r', 'e', 't', 'h', 'e', 'm', 'a', 'n', 'm', 'e', 'a', 's', 'u', 'r', 'e', 'd', 'm', 'y', 'h', 'e', 'i', 'g', 'h', 't', 't', 'o', 's', 'e', 'e', 'i', 'f', 'i', 'w', 'a', 's', 't', 'a', 'l', 'l', 'e', 'n', 'o', 'u', 'g', 'h', 'i', 'g', 'a', 'v', 'e', 't', 'h', 'e', 'm', 'a', 'n', 'm', 'y', 'c', 'o', 'i', 'n', 's', 'a', 's', 'k', 'e', 'd', 'f', 'o', 'r', 'c', 'h', 'a', 'n', 'g', 'e', 'a', 'n', 'd', 'j', 'u', 'm', 'p', 'e', 'd', 'o', 'n', 't', 'h', 'e', 'c', 'a', 'r', 't', 't', 'i', 'c', 'k', 't', 'i', 'c', 'k', 't', 'i', 'c', 'k', 't', 'h', 'e', 'c', 'a', 't', 'e', 'r', 'p', 'i', 'l', 'l', 'a', 'r', 'c', 'l', 'i', 'm', 'b', 'e', 'd', 's', 'l', 'o', 'w', 'l', 'y', 'u', 'p', 't', 'h', 'e', 't', 'r', 'a', 'c', 'k', 's', 'i', 't', 'w', 'e', 'n', 't', 's', 'o', 'h', 'i', 'g', 'h', 'i', 'c', 'o', 'u', 'l', 'd', 's', 'e', 'e', 't', 'h', 'e', 'p', 'a', 'r', 'k', 'i', 'n', 'g', 'l', 'o', 't', 'b', 'o', 'y', 'w', 'a', 's', 'i', 's', 'c', 'a', 'r', 'e', 'd', 'i', 't', 'h', 'o', 'u', 'g', 'h', 't', 't', 'o', 'm', 'y', 's', 'e', 'l', 'f', 't', 'h', 'e', 'r', 'e', '’', 's', 'n', 'o', 't', 'u', 'r', 'n', 'i', 'n', 'g', 'b', 'a', 'c', 'k', 'n', 'o', 'w', 'p', 'e', 'o', 'p', 'l', 'e', 'w', 'e', 'r', 'e', 's', 'o', 's', 'c', 'a', 'r', 'e', 'd', 't', 'h', 'e', 'y', 's', 'c', 'r', 'e', 'a', 'm', 'e', 'd', 'a', 's', 'w', 'e', 's', 'w', 'i', 'f', 't', 'l', 'y', 'z', 'o', 'o', 'm', 'e', 'd', 'f', 'a', 's', 't', 'f', 'a', 's', 't', 'a', 'n', 'd', 'f', 'a', 's', 't', 'e', 'r', 'a', 'l', 'o', 'n', 'g', 't', 'h', 'e', 't', 'r', 'a', 'c', 'k', 's', 'a', 's', 'q', 'u', 'i', 'c', 'k', 'l', 'y', 'a', 's', 'i', 't', 's', 't', 'a', 'r', 't', 'e', 'd', 't', 'h', 'e', 'c', 'a', 't', 'e', 'r', 'p', 'i', 'l', 'l', 'a', 'r', 'c', 'a', 'm', 'e', 't', 'o', 'a', 's', 't', 'o', 'p', 'u', 'n', 'f', 'o', 'r', 't', 'u', 'n', 'a', 't', 'e', 'l', 'y', 'i', 't', 'w', 'a', 's', 't', 'i', 'm', 'e', 't', 'o', 'p', 'a', 'c', 'k', 't', 'h', 'e', 'c', 'a', 'r', 'a', 'n', 'd', 'd', 'r', 'i', 'v', 'e', 'h', 'o', 'm', 'e', 't', 'h', 'a', 't', 'n', 'i', 'g', 'h', 't', 'i', 'd', 'r', 'e', 'a', 'm', 't', 'o', 'f', 't', 'h', 'e', 'w', 'i', 'l', 'd', 'r', 'i', 'd', 'e', 'o', 'n', 't', 'h', 'e', 'c', 'a', 't', 'e', 'r', 'p', 'i', 'l', 'l', 'a', 'r', 't', 'a', 'k', 'i', 'n', 'g', 'a', 't', 'r', 'i', 'p', 't', 'o', 't', 'h', 'e', 'a', 'm', 'u', 's', 'e', 'm', 'e', 'n', 't', 'p', 'a', 'r', 'k', 'a', 'n', 'd', 'r', 'i', 'd', 'i', 'n', 'g', 'o', 'n', 't', 'h', 'e', 'c', 'a', 't', 'e', 'r', 'p', 'i', 'l', 'l', 'a', 'r', 'w', 'a', 's', 'm', 'y', 'm', 'o', 's', 't', 'm', 'e', 'm', 'o', 'r', 'a', 'b', 'l', 'e', 'm', 'o', 'm', 'e', 'n', 't', 'e', 'v', 'e', 'r']\n  809 characters\n12.010765306122451\n"
          ]
        }
      ]
    }
  ]
}